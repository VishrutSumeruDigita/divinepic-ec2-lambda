# Dockerfile for PRODUCTION Environment (GPU-optimized)
FROM nvidia/cuda:11.8-devel-ubuntu20.04

# Prevent interactive prompts during build
ENV DEBIAN_FRONTEND=noninteractive

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-pip \
    python3-dev \
    build-essential \
    cmake \
    libopencv-dev \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    wget \
    curl \
    unzip \
    htop \
    nvtop \
    && rm -rf /var/lib/apt/lists/*

# Create symbolic link for python
RUN ln -s /usr/bin/python3 /usr/bin/python

# Upgrade pip
RUN python -m pip install --upgrade pip

# Set environment variables for CUDA and PRODUCTION
ENV CUDA_HOME=/usr/local/cuda
ENV LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
ENV PATH=$CUDA_HOME/bin:$PATH
ENV ENVIRONMENT=production
ENV DEVICE=cuda
ENV CUDA_VISIBLE_DEVICES=0

# Environment variables for better GPU performance
ENV OMP_NUM_THREADS=8
ENV MKL_NUM_THREADS=8
ENV NUMBA_CACHE_DIR=/tmp/numba_cache
ENV MPLCONFIGDIR=/app/.matplotlib
ENV INSIGHTFACE_ROOT=/app/.insightface
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# Create necessary directories
RUN mkdir -p /tmp/uploads \
    && mkdir -p /app/models \
    && mkdir -p /app/.insightface \
    && mkdir -p /app/.matplotlib \
    && mkdir -p /app/logs \
    && mkdir -p /tmp/numba_cache

# Download and setup AntelopeV2 model files
RUN cd /tmp && \
    wget -q https://github.com/deepinsight/insightface/releases/download/v0.7/antelopev2.zip && \
    unzip -q antelopev2.zip -d antelopev2_files && \
    mkdir -p /app/models/antelopev2/detection && \
    cp antelopev2_files/antelopev2/scrfd_10g_bnkps.onnx /app/models/antelopev2/detection/ && \
    cp antelopev2_files/antelopev2/glintr100.onnx /app/models/antelopev2/ && \
    rm -rf /tmp/antelopev2*

# Copy requirements and install Python dependencies
COPY requirements.prod.txt .
RUN pip install --no-cache-dir -r requirements.prod.txt

# Copy application files
COPY app.py .
COPY constants.py .

# Create environment file for production
RUN echo 'ENVIRONMENT=production\n\
DEVICE=cuda\n\
CUDA_VISIBLE_DEVICES=0\n\
AWS_REGION=ap-south-1\n\
S3_BUCKET_NAME=divinepic-prod\n\
S3_UPLOAD_PATH=upload_with_embed/prod\n\
ES_HOSTS1=http://3.6.116.114:9200\n\
INDEX_NAME=face_embeddings_prod\n\
FASTAPI_HOST=0.0.0.0\n\
FASTAPI_PORT=8000\n\
FACE_DETECTION_THRESHOLD=0.35\n\
FACE_DETECTION_SIZE=640\n\
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128' > .env

# Set permissions
RUN chmod -R 755 /app && \
    chmod 777 /tmp/uploads && \
    chmod 777 /tmp/numba_cache

# Expose port
EXPOSE 8000

# Health check with GPU verification
HEALTHCHECK --interval=30s --timeout=20s --start-period=120s --retries=5 \
    CMD curl -f http://localhost:8000/health && nvidia-smi || exit 1

# Create startup script for production environment
RUN echo '#!/bin/bash\n\
echo "Starting PRODUCTION FastAPI server (GPU mode)..."\n\
echo "Environment: $ENVIRONMENT"\n\
echo "Device: $DEVICE"\n\
echo "CUDA Visible Devices: $CUDA_VISIBLE_DEVICES"\n\
echo "GPU Status:"\n\
nvidia-smi\n\
echo "Starting FastAPI..."\n\
uvicorn app:app --host 0.0.0.0 --port 8000 --workers 1 &\n\
sleep 60\n\
echo "Warming up PRODUCTION model and GPU..."\n\
curl -f http://localhost:8000/health || echo "Health check failed"\n\
echo "PRODUCTION server ready!"\n\
wait' > /app/start.sh && chmod +x /app/start.sh

# Start the application
CMD ["/app/start.sh"] 